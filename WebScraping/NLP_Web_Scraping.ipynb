{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "from time import sleep\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "import pandas as pd\n",
    "#Name of Database File that Will be Created\n",
    "database = \"transcripts1.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create SQL Lite Connection\n",
    "def create_connection(db_file):\n",
    "    \"\"\" create a database connection to the SQLite database\n",
    "        specified by db_file\n",
    "    :param db_file: database file\n",
    "    :return: Connection object or None\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        return conn\n",
    "    except Error as e:\n",
    "        print(e)\n",
    " \n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect and Create Table Transcripts if the Table Doesn't Exist\n",
    "conn = create_connection(database)\n",
    "c = conn.cursor()\n",
    "c.execute('''CREATE TABLE IF NOT EXISTS TRANSCRIPTS ([TRANSCRIPTS] text PRIMARY KEY, [TICKER] text, [DATE] date,[TITLE] text)''')    \n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ATOS'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create list of tickers grouped up by exhange\n",
    "nsdq_ticks = \"data/nasdaqlisted.txt\"\n",
    "nyse_ticks = \"data/companylist.csv\"\n",
    "nyse = pd.read_csv(nyse_ticks)\n",
    "nsdq = pd.read_csv(nsdq_ticks,sep=\"|\")\n",
    "nsdq = nsdq[nsdq['Security Name'].str.contains(\"Common Stock\",na=False)]\n",
    "nsdq = nsdq[nsdq['ETF'].str.contains(\"N\",na=False)]\n",
    "nyse_tickers = list(nyse['Symbol']) \n",
    "nsdq_tickers = list(nsdq['Symbol'])\n",
    "nsdq_tickers[192]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search through tickers in nasdaq list, load firefox browser and downloaded earning transcript text  \n",
    "transcripts = []\n",
    "ticks = []\n",
    "\n",
    "for i in nsdq_tickers[194:]:\n",
    "    try:\n",
    "        for j in range(1,8):  \n",
    "            link ='https://www.fool.com/quote/nasdaq/apple/{}/earnings-call-transcripts'.format(i)\n",
    "            print(link)\n",
    "            driver = webdriver.Firefox()\n",
    "            driver.get(link)\n",
    "            sleep(3)\n",
    "            element = driver.find_element_by_xpath(\"/html/body/div[1]/div[2]/div/div/div[3]/div[2]/div[6]/div/div/article[{}]/div[2]/h4/a\".format(j))\n",
    "            element.click()\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            if \"Earnings\" in soup.find('h1').getText():  \n",
    "                title = soup.find('h1').getText()\n",
    "                transcript_soup = soup.find_all('p')[3:]            \n",
    "                try:\n",
    "                    date = soup.find(\"span\", id=\"date\").getText()\n",
    "                except:\n",
    "                    date = soup.find('h2').getText()\n",
    "                transcript = [i.getText() for i in transcript_soup]\n",
    "                c.execute('INSERT INTO TRANSCRIPTS VALUES (?,?,?,?)',[str(transcript),str(i),str(date),str(title)])\n",
    "                conn.commit()\n",
    "                driver.close()\n",
    "            else:\n",
    "                pass\n",
    "    except:\n",
    "        driver.close()\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search through tickers in nyse list, load firefox browser and downloaded earning transcript text \n",
    "for i in nyse_tickers[1501:]:\n",
    "    try:\n",
    "        for j in range(1,8):    \n",
    "            link ='https://www.fool.com/quote/nyse/apple/{}/earnings-call-transcripts'.format(i)\n",
    "            driver = webdriver.Firefox()\n",
    "            driver.get(link)\n",
    "            sleep(2)\n",
    "            element = driver.find_element_by_xpath(\"/html/body/div[1]/div[2]/div/div/div[3]/div[2]/div[6]/div/div/article[{}]/div[2]/h4/a\".format(j))\n",
    "            element.click()\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            if \"Earnings\" in soup.find('h1').getText():  \n",
    "                title = soup.find('h1').getText()\n",
    "                transcript_soup = soup.find_all('p')[3:]            \n",
    "                try:\n",
    "                    date = soup.find(\"span\", id=\"date\").getText()\n",
    "                except:\n",
    "                    date = soup.find('h2').getText()\n",
    "                transcript = [i.getText() for i in transcript_soup]\n",
    "                c.execute('INSERT INTO TRANSCRIPTS VALUES (?,?,?,?)',[str(transcript),str(i),str(date),str(title)])\n",
    "                conn.commit()\n",
    "                driver.close()\n",
    "            else:\n",
    "                pass\n",
    "    except:\n",
    "        driver.close()\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize data for each transcript\n",
    "df = pd.read_sql_query('SELECT * FROM TRANSCRIPTS', conn)\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    df['DATE'][i] = df['DATE'][i].replace(\".\",\"\")\n",
    "    df['DATE'][i] = df['DATE'][i].replace(\",\",\"\")\n",
    "\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    if len(df['DATE'][i]) <20:\n",
    "        try:\n",
    "            df['DATE'][i] =  datetime.strptime(df['DATE'][i].strip(), '%b %d %Y')\n",
    "        except:\n",
    "            df['DATE'][i] =  datetime.strptime(df['DATE'][i].strip(), '%B %d %Y')\n",
    "    else:\n",
    "        try:\n",
    "            df['DATE'][i] = df['DATE'][i].split(\"ending\",1)[1].strip()\n",
    "            df['DATE'][i] =  datetime.strptime(df['DATE'][i].strip(), '%b %d %Y')\n",
    "        except:\n",
    "            try:\n",
    "                df['DATE'][i] =  datetime.strptime(df['DATE'][i].strip(), '%B %d %Y')\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View Transcripts\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Close Connection\n",
    "c.execute('DROP TABLE TRANSCRIPTS')\n",
    "conn.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
