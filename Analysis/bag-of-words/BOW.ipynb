{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from FULL_DATA.ipynb\n",
      "importing Jupyter notebook from Create_Labels.ipynb\n",
      "(6380, 4)\n",
      "4377\n",
      "(4400, 7)\n",
      "(4377, 7)\n",
      "(4437, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\grays\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\grays\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import matplotlib.pyplot as plt\n",
    "from FULL_DATA import final_df\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    2367\n",
       "-1    1144\n",
       " 1     866\n",
       "Name: SENTIMENT, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['SENTIMENT'] = [-1 if (x > 1 and x<3.4999) else 0 if (x > 3.5 and x<4.49999) else 1  for x in final_df['ratings']]\n",
    "final_df['SENTIMENT'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Multi-class text classification\n",
    "default_pattern =  r\"\"\"(?x)                  \n",
    "                        (?:[A-Z]\\.)+          \n",
    "                        |\\$?\\d+(?:\\.\\d+)?%?    \n",
    "                        |\\w+(?:[-']\\w+)*      \n",
    "                        |\\.\\.\\.               \n",
    "                        |(?:[.,;\"'?():-_`])    \n",
    "                    \"\"\"\n",
    "def tokenize(text, pattern = default_pattern):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return regexp_tokenize(text, pattern)\n",
    "final_df['TOKENIZED_TRANSCRIPT'] = final_df.apply(lambda row: tokenize(row['TRANSCRIPTS']), axis=1)\n",
    "final_df['TOKENIZED_TRANSCRIPT'] = final_df['TOKENIZED_TRANSCRIPT'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range = (1,1),max_df = .9,min_df=.1)\n",
    "text_counts = cv.fit_transform(final_df['TOKENIZED_TRANSCRIPT'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    text_counts, final_df['SENTIMENT'], test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MultinomialNB Accuracy: 0.4726027397260274\n",
      "MultinomialNB F1: 0.4678522621487973\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB().fit(X_train, y_train)\n",
    "clf = MultinomialNB().fit(X_train, y_train)\n",
    "print(\"Test MultinomialNB Accuracy:\",metrics.accuracy_score(y_test, clf.predict(X_test)))\n",
    "print(\"MultinomialNB F1:\",metrics.f1_score(y_test, clf.predict(X_test),average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Accuracy: 0.6293759512937596\n",
      "Logistic F1: 0.5794550298189284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grays\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=1, multi_class= 'multinomial',solver = 'lbfgs',max_iter=200).fit(X_train, y_train)\n",
    "print(\"Logistic Accuracy:\",metrics.accuracy_score(y_test, clf.predict(X_test)))\n",
    "print(\"Logistic F1:\",metrics.f1_score(y_test, clf.predict(X_test),average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RF Accuracy: 0.558599695585997\n",
      "RF F1: 0.2389322916666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grays\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=5, random_state=1,n_estimators=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Test RF Accuracy:\",metrics.accuracy_score(y_test, clf.predict(X_test)))\n",
    "print(\"RF F1:\",metrics.f1_score(y_test, clf.predict(X_test),average = 'macro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
